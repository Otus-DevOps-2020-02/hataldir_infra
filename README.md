# hataldir_infra
hataldir Infra repository

[![Build Status](https://travis-ci.org/Otus-DevOps-2020-02/hataldir_infra.svg?branch=master)](https://travis-ci.org/Otus-DevOps-2020-02/hataldir_infra)

Домашнее задание № 11

Vagrant.

Установлен VirtualBox (с установкой огромого количества библиотек по причине серверной, а не десктопной версии Ubuntu и включением VT-x на виртуалке). Установлен Vagrant.
Описаны в Vagrantfile две машины - dbserver и appserver. В каждую из них добавлены провиженеры, вызывающие наш плейбук site.yml с соответствующим инвентори.
Установка питона в машины с помощью отдельного плейбука не понадобилась.

В роль db добавлена установка MongoDB из в виде плейбука install_mongo.yml и вынесена из плейбука main.yml в config_mongo.yml настройка MongoDB.

В роль app добавлена установка Ruby в виде плейбука ruby.yml. настройка puma вынесена в отдельный плейбук puma.yml.
Файл puma.service преобразован в темплейт, в нем и во всех плейбуках захардкоденное имя пользователя appuser заменено на переменную deploy_user. В Vagrantfile эта переменная определена как "vagrant".

Выполнены все провиженеры, инфраструктура поднята на vagrant.

Molecule.

Установлены virtualenv, Molecule, Testinfra. Установлен не упомянутый в описании ДЗ molecule-vagrant.

В molecule инициализирована роль db. Написан тест test_default.py.
В файл molecule.yml внесены нужные нам драйвер (vagrant), провайдер (virtualbox), образ (ubuntu/xenial64), не упомянутый в описании ДЗ verifier (testinfra).
Создан инстанс (molecule create).
Внесены изменения в файл converge.yml (теперь он называется не playbook.yml) - become:true и переменная mongo_bind_ip.
Конвергенция выполнена (molecule converge).
Проведены тесты (molecule verify).
В test_default.py внесен еще один тест - проверка доступности порта 27017 (модуль socket). Проверка выполнена.






Дополнительное задание 1:

Настройки nginx внесены в плейбук app.yml.







Домашнее задание № 10

Плейбуки app и db преобразованы в роли.
Созданы окружения stage и prod.
В app добавлена community роль jdauphant.nginx. В терраформ добавлено создание правила фаерволла, открывающего 80 порт.
Создан плейбук users.yml для добавления пользователей на виртуалки. Список пользователей берется из файла credentials.yml, разного для разных окружений. Файлы credentials.yml зашифрованы ansible-vault.


Дополнительное задание 1

Сделано в прошлом ДЗ, только изменены пути в конфигах терраформа. Разные для stage и prod.

Дополнительное задание 2

Установлены tflint, ansible-lint. Добавлены проверки packer, terraform, ansible в .travis.yml. Добавлен badge TravisCI в readme.
Установлен trytravis, создан для него репозиторий в github. На нем проведена отладка работы TravisCi.


Домашнее задание № 9

Создан плейбук reddit_app.yml для настройки служб на виртуалках app и db. Для настроек mongodb и для прописывания адреса db в службе puma созданы темплейты.
В плейбуке выделено три отдельных сценария.
Каждый сценарий вынесен в отдельный плейбук - db, app, deploy. Создан плейбук site, включающий (import) все эти три.
Созданы еще два плейбука - packer_app.yml и packer_db.yml, реализующие при создании образов те настройки, которые раньше выполнялись bash-скриптами.

Дополнительное задание

В терраформе создан темплейт, формирующий файл inventory.yml для ансибла с актуальными адресами машин.
В него же вынесена переменная db_host из app.yml.



Домашнее задание № 8

После удаления каталога ~/reddit задача Clone repo из плейбука отрабатывает со статусом changed, так как приложения на хосте нет.

Дополнительное задание:

Inventory создано в динамическом формате JSON и написан скрипт, отдающий его при запуске с параметром --list. При запуске с параметром --host он отдает пустой список, так как этот параметр является необязательным.
В ansible.cfg в строке inventory указан этот скрипт.
Отличие динамического от статического JSON - должна присутствовать секция _meta, в которой находятся все переменные.



Домашнее задание № 7

В инфраструктуру terraform импортировано правило фаерволла default-allow-ssh.
Зарезервирован для приложения постоянный ip адрес.
С помощью Packer созданы отдельные образы db и app.
Конфигурация terraform разделена на файлы app.tf, db.tf, vpc.tf и затем преобразована в модули.
В модуле vpc предусмотрено использование переменной для определения диапазона разрешенных хостов.
Созданы два окружения prod и stage, отличающиеся именно этим диапазоном.
С помощью модуля storage-bucket создан бакет.

Дополнительное задание 1

Для окружений prod и stage настроены remote backends - хранение состояния в бакете.

Дополнительное задание 2

В модуль app добавлены provisioners для деплоя приложения. Адрес виртуалки db передается в виртуалку app и добавляется в puma.service.






Домашнее задание № 6

Установлен terraform, удален ключ appuser из метаданных проекта
Создан конфигурационный файл main.tf для разворачивание машины reddit-app, аналогичной предыдущему ДЗ.
Часть параметров из этого файла вынесена в переменные в файлах variables.tf и terraform.tfvars

Дополнительное задание 1:

Добавлены ключи для пользователей appuser1, appuser2 через terraform и appuser-web через веб-интерфейс. Проблемы:
 - ключи appuser, appuser1, appuser2 должный идти в одной строек, разделенные \n
 - ключи, добавляемые через terraform, не видны в веб-интерфейсе

Дополнительное задание 2:

С помощью terraform создан балансировщик нагрузки, состоящий из следующих ресурсов:
 - global forwarding rule
 - target http proxy
 - backend service
 - instance group
 - healthcheck
 - url-map
 - переменная с его адресом

Затем в создание инстанса app добавлен параметр count и изменен name, так же изменена ссылка на инстансы и добавлен второй инстанс в instance group в lb.tf и изменена ссылка и добавлена вторая переменная в outputs.tf.
Проверена работа балансировщика при остановке службы puma на одном из инстансов.

Пока не разобрался как запустить балансировщик на нестандартном порту, но это пока не нужно.



Домашнее задание № 5

Установлены Packer, ADC
Для Packer создан шаблон ubuntu16.json для создания образа ВМ из предыдущего ДЗ со всеми зависимостями но без приложения.
В шаблоне часть параметров вынесена в переменные, добавлены новые параметры.

Дополнительное задание 1:

Создан шаблон immutable.json, в котором добавлено также и приложение reddit (для которого написан systemd unit).

Дополнительное задание 1:

Написан скрипт create-reddit-vm.sh для создания ВМ из образа с помощью gcloud


testapp_IP = 35.195.223.202
testapp_port = 9292

Домашнее задание № 4

Установлен gcloud, с его помощью создана ВМ reddit-app, на нее поставлены ruby, bundler, mongodb и тестовое приложение. К ВМ предоставлен доступ на порт 9292.
Для установки пакетов и запуска приложения написаны скрипты.

Дополнительное задание 1:

Написан скрипт startup_script, добавлен в команду создания ВМ:

gcloud compute instances create reddit-app2  --boot-disk-size=10GB   --image-family ubuntu-1604-lts   --image-project=ubuntu-os-cloud   --machine-type=g1-small   --tags puma-server   --restart-on-failure --metadata-from-file startup-script=startup_script.sh


Дополнительное задание 2:

Создано правило фаерволла с помощью gcloud:

gcloud compute firewall-rules create default-puma-server --allow tcp:9292 --target-tags=puma-server



bastion_IP = 35.210.206.2
someinternalhost_IP = 10.132.0.3

Домашнее задание № 3

Конфигурация:

Созданы две виртуальные машины в GCP - bastion и someinternalhost.
У bastion два интерфейса с адресами 35.210.206.2 и 10.132.0.2, у someinternalhost - один, 10.132.0.3.
На bastion установлен VPN-сервер pritunl, работающий на порту 15586/udp. На сервере есть один пользователь test.
Подключение к серверу bastion можно осуществить с использованием конфигурационного файла cloud-bastion.ovpn.


Дополнительное задание 1:

Для подключения к серверу someinternalhost одной командой ssh someinternalhost достаточно создать файл ~/.ssh/config со следующим содержимым:
host someinternalhost
 HostName 10.132.0.3
 ProxyJump appuser@35.210.206.2:22
 User appuser
 IdentityFile ~/.ssh/appuser


Дополнительное задание 2:

 На сервер pritunl установлен сертификат от Let's Encrypt. Для проверки нужно заходить на адрес https://35.210.206.2.sslip.io
